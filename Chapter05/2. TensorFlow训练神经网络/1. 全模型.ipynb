{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "# TensorFlow 提供了一个类来处理minist 数据集。自动下载并转化格式\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.设置输入和输出节点的个数,配置神经网络的参数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_NODE = 784     # 输入节点 28x28=784\n",
    "OUTPUT_NODE = 10     # 输出节点 0~9\n",
    "LAYER1_NODE = 500    # 隐藏层数       \n",
    "                              \n",
    "BATCH_SIZE = 100     # 每次batch打包的样本个数        \n",
    "\n",
    "# 模型相关的参数\n",
    "LEARNING_RATE_BASE = 0.8   # origin learning rate    \n",
    "LEARNING_RATE_DECAY = 0.99  # decay\n",
    "REGULARAZTION_RATE = 0.0001  # weight regulazation lambda\n",
    "TRAINING_STEPS = 10000        \n",
    "MOVING_AVERAGE_DECAY = 0.99  # 滑动平均decay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. 定义辅助函数来计算前向传播结果，使用ReLU做为激活函数。\n",
    "#### three layers, 1 input data, 1 hidden layer, 1 output layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(input_tensor, avg_class, weights1, biases1, weights2, biases2):\n",
    "    # 不使用滑动平均类\n",
    "    if avg_class == None:\n",
    "        layer1 = tf.nn.relu(tf.matmul(input_tensor, weights1) + biases1)\n",
    "        return tf.matmul(layer1, weights2) + biases2\n",
    "\n",
    "    else:\n",
    "        # 使用滑动平均类\n",
    "        layer1 = tf.nn.relu(tf.matmul(input_tensor, avg_class.average(weights1)) + avg_class.average(biases1))\n",
    "        return tf.matmul(layer1, avg_class.average(weights2)) + avg_class.average(biases2)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. 定义训练过程。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(mnist):\n",
    "    x = tf.placeholder(tf.float32, [None, INPUT_NODE], name='x-input') # [batch,784]\n",
    "    y_ = tf.placeholder(tf.float32, [None, OUTPUT_NODE], name='y-input') # [batch,10]\n",
    "    # 生成隐藏层的参数。\n",
    "    # truncated_normal:截断高斯函数(<2*stddev)　P67,table3-2\n",
    "    weights1 = tf.Variable(tf.truncated_normal([INPUT_NODE, LAYER1_NODE], stddev=0.1)) # [784,500]\n",
    "    biases1 = tf.Variable(tf.constant(0.1, shape=[LAYER1_NODE]))\n",
    "    # 生成输出层的参数。\n",
    "    weights2 = tf.Variable(tf.truncated_normal([LAYER1_NODE, OUTPUT_NODE], stddev=0.1))\n",
    "    biases2 = tf.Variable(tf.constant(0.1, shape=[OUTPUT_NODE]))\n",
    "\n",
    "    # 计算不含滑动平均类的前向传播结果\n",
    "    y = inference(x, None, weights1, biases1, weights2, biases2)\n",
    "    \n",
    "    # 定义训练轮数及相关的滑动平均类 \n",
    "    global_step = tf.Variable(0, trainable=False)\n",
    "    # Average class\n",
    "    variable_averages = tf.train.ExponentialMovingAverage(MOVING_AVERAGE_DECAY, global_step)\n",
    "    # 定义一个更新滑动平均的操作。\n",
    "    variables_averages_op = variable_averages.apply(tf.trainable_variables())\n",
    "    # 滑动平均输出\n",
    "    average_y = inference(x, variable_averages, weights1, biases1, weights2, biases2)\n",
    "    \n",
    "    # 计算交叉熵及其平均值\n",
    "    # tf.nn.softmax_cross_entropy_with_logits() = softmax + cross_entropy\n",
    "    # 在只有一个答案的分类问题中，只用`sparse_softmax_cross_entropy_with_logits`加速计算\n",
    "    cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=y, labels=tf.argmax(y_, 1))\n",
    "    cross_entropy_mean = tf.reduce_mean(cross_entropy)\n",
    "    \n",
    "    # 损失函数的计算\n",
    "    regularizer = tf.contrib.layers.l2_regularizer(REGULARAZTION_RATE)\n",
    "    regularaztion = regularizer(weights1) + regularizer(weights2)\n",
    "    # Total loss\n",
    "    loss = cross_entropy_mean + regularaztion\n",
    "    \n",
    "    # 设置指数衰减的学习率。\n",
    "    learning_rate = tf.train.exponential_decay(\n",
    "        LEARNING_RATE_BASE, # starter learning rate\n",
    "        global_step,\n",
    "        mnist.train.num_examples / BATCH_SIZE, # decay_steps, # 衰减速度\n",
    "        LEARNING_RATE_DECAY,\n",
    "        staircase=True)\n",
    "    \n",
    "    # 优化损失函数\n",
    "    train_step = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss, global_step=global_step)\n",
    "    \n",
    "    # 反向传播更新参数和更新每一个参数的滑动平均值\n",
    "    # 为了一次完成更新参数和滑动平均参数,tf提供了`tf.control_dependencies` 和`tf.group`两种机制。\n",
    "    # 等价于：train_op = tf.group(train_step, variables_averages_op)\n",
    "    with tf.control_dependencies([train_step, variables_averages_op]):\n",
    "        train_op = tf.no_op(name='train')\n",
    "\n",
    "    # 计算正确率\n",
    "    # tf.argmax: Returns the index with the largest value across axes of a tensor.\n",
    "    # tf.equal: Returns the truth value of (x == y) element-wise.\n",
    "    # correct_prediction.shape: [batch_size,1]\n",
    "    correct_prediction = tf.equal(tf.argmax(average_y, 1), tf.argmax(y_, 1)) # axis=1,along colums\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32)) # A float number.\n",
    "    \n",
    "    # 初始化会话，并开始训练过程。\n",
    "    with tf.Session() as sess:\n",
    "        tf.global_variables_initializer().run() # Init all variables\n",
    "        validate_feed = {x: mnist.validation.images, y_: mnist.validation.labels}\n",
    "        test_feed = {x: mnist.test.images, y_: mnist.test.labels} \n",
    "        \n",
    "        # 循环的训练神经网络。\n",
    "        for i in range(TRAINING_STEPS):\n",
    "            if i % 1000 == 0:\n",
    "                validate_acc = sess.run(accuracy, feed_dict=validate_feed)\n",
    "                print(\"After %d training step(s), validation accuracy using average model is %g \" % (i, validate_acc))\n",
    "            # Feed train data.\n",
    "            xs,ys=mnist.train.next_batch(BATCH_SIZE)\n",
    "            sess.run(train_op,feed_dict={x:xs,y_:ys})\n",
    "\n",
    "        test_acc=sess.run(accuracy,feed_dict=test_feed)\n",
    "        print((\"After %d training step(s), test accuracy using average model is %g\" %(TRAINING_STEPS, test_acc)))\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. 主程序入口，这里设定模型训练次数为5000次。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../../0_datasets/MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting ../../0_datasets/MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting ../../0_datasets/MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting ../../0_datasets/MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "correct_prediction.shape:  (?,)\n",
      "accuracy.shape:  ()\n",
      "After 0 training step(s), validation accuracy using average model is 0.116 \n",
      "After 1000 training step(s), validation accuracy using average model is 0.977 \n",
      "After 2000 training step(s), validation accuracy using average model is 0.982 \n",
      "After 3000 training step(s), validation accuracy using average model is 0.9836 \n",
      "After 4000 training step(s), validation accuracy using average model is 0.9834 \n",
      "After 5000 training step(s), validation accuracy using average model is 0.9846 \n",
      "After 6000 training step(s), validation accuracy using average model is 0.9828 \n",
      "After 7000 training step(s), validation accuracy using average model is 0.9838 \n",
      "After 8000 training step(s), validation accuracy using average model is 0.9842 \n",
      "After 9000 training step(s), validation accuracy using average model is 0.9852 \n",
      "After 10000 training step(s), test accuracy using average model is 0.9833\n"
     ]
    }
   ],
   "source": [
    "def main(argv=None):\n",
    "    mnist = input_data.read_data_sets(\"../../0_datasets/MNIST_data/\", one_hot=True)\n",
    "    train(mnist)\n",
    "\n",
    "if __name__=='__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
